{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "pu5oit3smz43evzufdjv",
   "authorId": "8277624389373",
   "authorName": "EPALK",
   "authorEmail": "egle.palk@solita.ee",
   "sessionId": "eac9df3e-8b0e-41c4-ba38-d0ee14046cd9",
   "lastEditTime": 1758613518059
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "name": "introIntro",
    "collapsed": false
   },
   "source": "# Hands-on lab for Tallinn Data Week \n\nWelcome to this hands-on workshop, which is part of the [Tallinn Data Week](https://fienta.com/tallinn-data-week-2025-snowflake) program. The goal of this workshop is to give you practical experience with Snowflake by combining concepts from modern data engineering pipelines with elements of data processing using Modin and Cortex.\n\nBefore we start, please make sure you have a Snowflake trial account set up: https://signup.snowflake.com \n\nWhen signing up, select the cloud provider **AWS** and a region **EU (Frankfurt)**. This ensures faster performance and better alignment with the resources you’ll use in the workshop.\n\nOnce your account is ready, we will walk through how to import a Jupyter notebook directly in the Snowflake UI. You can also see the steps from here:\n\n1. Download the [notebook](https://github.com/solita/tallinn-data-week-snowflake/blob/main/TDW_SNOWFLAKEDATAENGINEERING.ipynb)\n2. Log in to your Snowflake UI.\n3. Click the + Create button on the left sidebar.\n4. Choose Notebook → Import .ipynb File\n4. For database, select SNOWFLAKE_LEARNING_DB.\n5. For schema, select PUBLIC.\n6. Keep the runtime and runtime warehouse as the default.\n7. Keep query warehouse as COMPUTE_WH and notebook warehouse as SYSTEM$STREAMLIT_NOTEBOOK_WH.\n8. Finally, click Create to import the notebook into your environment.\n\nThe notebook will contain step-by-step instructions, this will allow you to follow along with the exercises and run the queries on your own environment.\n\n## What This Workshop Covers\n\n1. Data Engineering Foundations\n- How to set up stages and file formats.\n- Loading raw CSV data into Snowflake tables.\n- Transforming and cleaning the data with SQL and views.\n- Doing analytical queries\n2. Extending with Modin and Cortex\n- Applying Cortex features to enrich the dataset. It covers:\n  - Classification function\n  - Translation function\n  - Summarisation function\n  - Sentiment Analysis\n- Using the GET_LINEAGE function to understand data dependencies and flows.\n- Building a simple Streamlit app to demonstrate your results.\n"
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "SQLSetContext"
   },
   "source": "use role sysadmin;\nCREATE OR REPLACE DATABASE avalanche;\nCREATE OR REPLACE SCHEMA raw;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "219cc8b1-c225-4b43-aacf-9ef43985c62f",
   "metadata": {
    "name": "introFileFormat",
    "collapsed": false
   },
   "source": "Let's create a FILE FORMAT object. A FILE FORMAT describes a set of staged data."
  },
  {
   "cell_type": "code",
   "id": "c71dd7f6-b6f5-4e38-b19c-a882d9309360",
   "metadata": {
    "language": "sql",
    "name": "SQLFileFormat"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE FILE FORMAT avalanche.raw.csv_ff\n  TYPE = 'CSV'\n  FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n  FIELD_DELIMITER = ','\n  SKIP_HEADER = 1;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2b054624-5550-451f-8da3-4a3a1988eca4",
   "metadata": {
    "name": "introStage",
    "collapsed": false
   },
   "source": "Next, let's create a STAGE. In Snowflake, a STAGE defines a location in cloud storage, where files are stored for loading (or unloading)."
  },
  {
   "cell_type": "code",
   "id": "78a58e17-968e-4754-886e-a48223ecc354",
   "metadata": {
    "language": "sql",
    "name": "SQLStage"
   },
   "outputs": [],
   "source": "-- create stage  \nCREATE OR REPLACE STAGE avalanche.raw.avalanche\nurl = 's3://sfquickstarts/misc/avalanche/csv/'\nfile_format = avalanche.raw.csv_ff;\n\n-- see what is in the stage\nls @avalanche;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "56820bfd-d742-4e65-b003-707f8f7f6452",
   "metadata": {
    "name": "introCreateTable",
    "collapsed": false
   },
   "source": "We will create a couple of tables, PRODUCT_CATALOG and ORDER_HISTORY, and load them."
  },
  {
   "cell_type": "code",
   "id": "2d28ea5e-8eda-4595-bf11-c72dd5c47fe0",
   "metadata": {
    "language": "sql",
    "name": "SQLCreateTable"
   },
   "outputs": [],
   "source": "-- product catalog table build\nCREATE OR REPLACE TABLE AVALANCHE.RAW.PRODUCT_CATALOG\n(\n   NAME VARCHAR(16777216),\n   DESCRIPTION VARCHAR(16777216),\n   PRICE VARCHAR(16777216)\n);\n\n-- create table for order, more to analyze in here\nCREATE OR REPLACE TABLE AVALANCHE.RAW.ORDER_HISTORY (\n  ORDER_ID      VARCHAR(100),\n  CUSTOMER_ID   VARCHAR(100),\n  PRODUCT_ID    VARCHAR(100),\n  PRODUCT_NAME  VARCHAR(16777216),\n  QUANTITY_ORDERED INTEGER,\n  PRICE         VARCHAR(16777216),\n  TOTAL_PRICE   VARCHAR(16777216),\n  ORDER_DATE    DATE\n);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0c9374ab-4c65-4b03-b7fe-5bfde2542ce7",
   "metadata": {
    "language": "sql",
    "name": "SQLSelectDataInStage"
   },
   "outputs": [],
   "source": "SELECT t.$1, t.$2, t.$3  FROM @avalanche/product-catalog.csv (file_format => 'avalanche.raw.csv_ff') t;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "638bf645-dde7-4e4a-8862-2ddf9b30951c",
   "metadata": {
    "language": "sql",
    "name": "SQLLoadProducts"
   },
   "outputs": [],
   "source": "-- product catalog table load\nCOPY INTO avalanche.raw.product_catalog\nFROM @avalanche/product-catalog.csv;\n\n-- check the table\nSELECT * FROM avalanche.raw.product_catalog;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70a41d14-9901-4663-b258-bf00d611b189",
   "metadata": {
    "language": "sql",
    "name": "SQLLoadOrders"
   },
   "outputs": [],
   "source": "COPY INTO AVALANCHE.RAW.ORDER_HISTORY\nFROM @avalanche/order-history.csv;\n\nselect * from AVALANCHE.RAW.ORDER_HISTORY;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f79d8791-03dd-4f4f-abc3-ac51df7c2857",
   "metadata": {
    "name": "introTransformations",
    "collapsed": false
   },
   "source": "Now that our raw data is loaded into Snowflake tables, let's do some transformations."
  },
  {
   "cell_type": "code",
   "id": "f28892a9-6f2f-4445-af48-4369140a0273",
   "metadata": {
    "language": "sql",
    "name": "SQLNewSchema"
   },
   "outputs": [],
   "source": "-- create a fresh schema\nCREATE OR REPLACE SCHEMA AVALANCHE.TRF;\nUSE SCHEMA AVALANCHE.TRF;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "42b92834-b622-4964-a035-ab9b64b181f0",
   "metadata": {
    "name": "introUDF",
    "collapsed": false
   },
   "source": "In the data we loaded, the PRICE column is a string, and it looks like a US price with a dollar sign. We would rather store this as a number, so that we can aggregate and analyze it. \n\nLet's create a UDF called CLEAN_PRICE to clean the PRICE column, and then use that UDF to create some views with cleaned data. "
  },
  {
   "cell_type": "code",
   "id": "da1316fe-1325-49da-a4b1-e6f227334163",
   "metadata": {
    "language": "sql",
    "name": "SQLFunction"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE FUNCTION TRF.CLEAN_PRICE(s STRING)\nRETURNS NUMBER(18,2)\nAS\n$$\n  TRY_TO_DECIMAL(REGEXP_REPLACE(s, '[^0-9\\\\.-]', ''), 18, 2)\n$$;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf2f690d-3ed9-45dd-b61f-6b512bac2972",
   "metadata": {
    "language": "sql",
    "name": "SQLCleanProducts"
   },
   "outputs": [],
   "source": "\nCREATE OR REPLACE VIEW PRODUCTS AS\nSELECT\n  NAME,\n  DESCRIPTION,\n  TRF.CLEAN_PRICE(PRICE) AS PRICE_NUM, -- remove $ and cast price to numeric\n  -- also create groupings using basic string functions\n  IFF(LOWER(NAME) LIKE '%ski%' OR LOWER(DESCRIPTION) LIKE '%ski%', 'ski', NULL) AS CAT_SKI,\n  IFF(LOWER(NAME) LIKE '%boot%' OR LOWER(DESCRIPTION) LIKE '%boot%', 'boot', NULL) AS CAT_BOOT,\n  IFF(LOWER(NAME) LIKE '%helmet%' OR LOWER(DESCRIPTION) LIKE '%helmet%', 'helmet', NULL) AS CAT_HELMET,\n  IFF(LOWER(NAME) LIKE '%jacket%' OR LOWER(DESCRIPTION) LIKE '%jacket%', 'jacket', NULL) AS CAT_JACKET\nFROM AVALANCHE.RAW.PRODUCT_CATALOG;\n\nselect * from PRODUCTS;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5de6ab24-3235-4858-bf98-2596d805b853",
   "metadata": {
    "language": "sql",
    "name": "SQLCleanOrders"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE VIEW ORDERS AS\nSELECT\n  ORDER_ID,\n  CUSTOMER_ID,\n  PRODUCT_ID,\n  PRODUCT_NAME,\n  TRY_TO_NUMBER(QUANTITY_ORDERED) AS QTY, -- TRY_TO functions can be helpful when you just want to get what is valid\n  TRF.CLEAN_PRICE(PRICE) AS UNIT_PRICE, -- cleaned price\n-- now use both to make a review column\n  COALESCE(\n    TRF.CLEAN_PRICE(PRICE) * TRY_TO_NUMBER(QUANTITY_ORDERED),\n    TRF.CLEAN_PRICE(PRICE)\n  ) AS TOTAL_PRICE_NUM,\n  TO_DATE(ORDER_DATE) AS ORDER_DATE\nFROM AVALANCHE.RAW.ORDER_HISTORY;\n\nselect * from ORDERS;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "acad04aa-c260-47dd-804d-f2427475e838",
   "metadata": {
    "name": "introAnalysis",
    "collapsed": false
   },
   "source": "Let's play around a bit and do some basic analyis. This is often the kinds of calculations you would want for reports."
  },
  {
   "cell_type": "code",
   "id": "96a8b28f-47c3-477f-a24e-fda68a11f369",
   "metadata": {
    "language": "sql",
    "name": "SQLRevenue"
   },
   "outputs": [],
   "source": "-- Revenue by month\nSELECT DATE_TRUNC('month', ORDER_DATE) AS month, ROUND(SUM(TOTAL_PRICE_NUM),2) AS revenue\nFROM ORDERS\nGROUP BY 1\nORDER BY 1;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e22bf2ec-120f-4c34-88b7-7ab03543d227",
   "metadata": {
    "language": "sql",
    "name": "SQLRevenueTopProducts"
   },
   "outputs": [],
   "source": "-- Top products by revenue\nSELECT \n    PRODUCT_NAME, \n    ROUND(SUM(TOTAL_PRICE_NUM),2) AS REVENUE, \n    SUM(QTY) AS QTY\nFROM ORDERS\nGROUP BY PRODUCT_NAME\nORDER BY REVENUE DESC;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "225f4467-58b5-47dd-b30c-3f5b33a80fc6",
   "metadata": {
    "language": "sql",
    "name": "SQLPriceVsDemand"
   },
   "outputs": [],
   "source": "-- Price vs. demand \nSELECT \n    ROUND(UNIT_PRICE,2) AS PRICE, \n    SUM(QTY) AS QTY\nFROM ORDERS\nWHERE UNIT_PRICE IS NOT NULL\nGROUP BY 1\nORDER BY 1;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a7377177-89b3-443b-a0b1-b08f5c4c9dbc",
   "metadata": {
    "language": "sql",
    "name": "SQLSalesView"
   },
   "outputs": [],
   "source": "--  Create sales enriched view by combining orders and product category\nCREATE OR REPLACE VIEW SALES_ENRICHED AS\nSELECT\n  o.ORDER_ID,\n  o.CUSTOMER_ID,\n  o.ORDER_DATE,\n  o.PRODUCT_ID,\n  o.PRODUCT_NAME,\n  o.QTY,\n  o.UNIT_PRICE,\n  o.TOTAL_PRICE_NUM,\n  p.PRICE_NUM AS CATALOG_PRICE\nFROM ORDERS o\nLEFT JOIN PRODUCTS p\n  ON o.PRODUCT_NAME = p.NAME  \n;\n\nSELECT * FROM SALES_ENRICHED;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "690baa66-0c1b-4445-9a8b-febab75acdfd",
   "metadata": {
    "language": "sql",
    "name": "SQLPriceComparison"
   },
   "outputs": [],
   "source": "-- Catalog Price vs. Order Price\nSELECT PRODUCT_NAME,\n       ROUND(AVG(UNIT_PRICE), 2)   AS avg_sold_price,\n       ROUND(AVG(CATALOG_PRICE),2) AS avg_catalog_price,\n       ROUND(SUM(TOTAL_PRICE_NUM),2) AS total_revenue\nFROM SALES_ENRICHED\nGROUP BY PRODUCT_NAME\nORDER BY total_revenue DESC;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0ff08016-d812-40ca-a8d1-aa5f555b2e00",
   "metadata": {
    "name": "introCortex",
    "collapsed": false
   },
   "source": "Snowflake Cortex offers powerful AI capabilities that you can apply directly to your data, transforming raw text into structured insights. These functions are built-in and ready to use."
  },
  {
   "cell_type": "markdown",
   "id": "c937cae9-ef1b-49df-8e0f-549239d21631",
   "metadata": {
    "name": "introClassification",
    "collapsed": false
   },
   "source": "Let's classify our products using the AISQL function AI_CLASSIFY. The syntax is \n\n```sql\nAI_CLASSIFY( <input> , <list_of_categories> [, <config_object>] )\n```"
  },
  {
   "cell_type": "code",
   "id": "6b505c3e-27da-45f2-ab38-d42ca7e868e8",
   "metadata": {
    "language": "sql",
    "name": "SQLClassifyStep1"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE PRODUCTS_CLASSIFY_1 AS\nSELECT\n  NAME,\n  DESCRIPTION,\n  PRICE_NUM, \n  AI_CLASSIFY(NAME, ['Apparel', 'Accessories']) as LABEL_1,\n  AI_CLASSIFY(DESCRIPTION, ['Apparel', 'Accessories']) as LABEL_2,\nFROM AVALANCHE.TRF.PRODUCTS;\n\n-- check the data\nSELECT * FROM PRODUCTS_CLASSIFY_1;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2a9b78c6-1e03-4045-b0df-2290b5934bca",
   "metadata": {
    "language": "sql",
    "name": "SQLClassifyStep2"
   },
   "outputs": [],
   "source": "-- extract the value from the JSON\nCREATE OR REPLACE TABLE PRODUCTS_CLASSIFY AS\nSELECT\n  NAME,\n  DESCRIPTION,\n  PRICE_NUM, \n  LABEL_1:labels[0]::string as CATEGORY_1,\n  LABEL_2:labels[0]::string as CATEGORY_2\nFROM AVALANCHE.TRF.PRODUCTS_CLASSIFY_1;\n\nselect * from PRODUCTS_CLASSIFY;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "94cc780e-173a-49b6-8549-9123c055655e",
   "metadata": {
    "name": "introTranslate",
    "collapsed": false
   },
   "source": "Snowflake Cortex makes language translation simple. Let's leverage Cortex's powerful TRANSLATE function to instantly localize our product information from English into a couple of different languages:"
  },
  {
   "cell_type": "code",
   "id": "39562d28-d0d6-4f54-b190-e3a14e46bdba",
   "metadata": {
    "language": "sql",
    "name": "SQLTranslate"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE PRODUCTS_TRANSLATE AS\nSELECT\n  NAME,\n  SNOWFLAKE.CORTEX.TRANSLATE(DESCRIPTION, 'en', 'sv') as DESCRIPTION_SWEDISH,\n  PRICE_NUM, \n  SNOWFLAKE.CORTEX.TRANSLATE(CATEGORY_1, 'en', 'fr') as CATEGORY_1_FRENCH,\n  SNOWFLAKE.CORTEX.TRANSLATE(CATEGORY_2, 'en', 'de') as CATEGORY_2_GERMAN\nFROM AVALANCHE.TRF.PRODUCTS_CLASSIFY;\n\nselect * from PRODUCTS_TRANSLATE;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "395c5367-60d1-43c4-ac02-9824d5041eeb",
   "metadata": {
    "name": "introSentiment",
    "collapsed": false
   },
   "source": "Ever wondered how your product descriptions are perceived? Are they overwhelmingly positive, or do they carry a hint of negativity? Let's use the AI_SENTIMENT function to assign a sentiment value to each description, instantly revealing its emotional tone:"
  },
  {
   "cell_type": "code",
   "id": "ea3db6a8-75f2-4dbe-925f-14bd70161ad4",
   "metadata": {
    "language": "sql",
    "name": "SQLSentiment"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE PRODUCTS_SENTIMENT AS\nWITH CTE_SENTIMENT AS (\n    SELECT\n      NAME,\n      DESCRIPTION,\n      AI_SENTIMENT(DESCRIPTION) as SENTIMENT_JSON,\n      PRICE_NUM, \n      CATEGORY_1,\n      CATEGORY_2\n    FROM AVALANCHE.TRF.PRODUCTS_CLASSIFY)\nSELECT \n    NAME,\n    DESCRIPTION,\n    --SENTIMENT_JSON,\n    t1.VALUE:sentiment::string as SENTIMENT,\n    PRICE_NUM, \n    CATEGORY_1,\n    CATEGORY_2\nFROM CTE_SENTIMENT\n, LATERAL FLATTEN( INPUT => SENTIMENT_JSON:categories ) t1\n;\n\nselect * from PRODUCTS_SENTIMENT;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8d366efe-3eea-46ad-b4ac-167a655f4cec",
   "metadata": {
    "name": "introSummarize",
    "collapsed": false
   },
   "source": "Long descriptions can be overwhelming. What if you could get the gist of a product description in a single, concise sentence? Cortex's SUMMARIZE function helps to distill lengthy text into digestible summaries."
  },
  {
   "cell_type": "code",
   "id": "d550225e-9901-4d4d-b736-d82f71dcda8c",
   "metadata": {
    "language": "sql",
    "name": "SQLSummarize"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE PRODUCTS_SUMMARIZE AS\nSELECT\n  NAME,\n  DESCRIPTION,\n  SNOWFLAKE.CORTEX.SUMMARIZE(DESCRIPTION) as DESCRIPTION_SUMMARY,\n  PRICE_NUM, \n  CATEGORY_1\n  CATEGORY_2\nFROM AVALANCHE.TRF.PRODUCTS_CLASSIFY;\n\nselect * from PRODUCTS_SUMMARIZE;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3086eb2f-c2df-4697-a282-8e4c8509eedb",
   "metadata": {
    "name": "introAISummarize",
    "collapsed": false
   },
   "source": "And sometimes you want to summarize *many rows all together*, to get the gist of what is happening *overall*. AI_SUMMARIZE_AGG is one of the aggregate AISQL functions, and it allows a quick overview."
  },
  {
   "cell_type": "code",
   "id": "d9ba3d6f-486c-403b-ad77-9a9ed653092f",
   "metadata": {
    "language": "sql",
    "name": "SQLAISummarize"
   },
   "outputs": [],
   "source": "-- bonus\nSELECT\n  AI_SUMMARIZE_AGG(DESCRIPTION) as DESCRIPTION_SUMMARY\nFROM AVALANCHE.TRF.PRODUCTS_CLASSIFY;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f965e218-5387-4874-b267-02d698044afc",
   "metadata": {
    "name": "introExtract",
    "collapsed": false
   },
   "source": "Sometimes, you need to pull out very specific pieces of information from unstructured text. The AI_EXTRACT function acts like a smart assistant, answering questions directly from your text. Let's use it to identify the exact product mentioned in each name, and if there are pockets."
  },
  {
   "cell_type": "code",
   "id": "a797d143-a602-45b5-abc0-100fbedf54c5",
   "metadata": {
    "language": "sql",
    "name": "SQLExtract"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE PRODUCTS_EXTRACT AS\nSELECT\n  NAME,\n  DESCRIPTION,\n  AI_EXTRACT(\n    text => DESCRIPTION,\n    responseFormat => {'product': 'What product is being mentioned?', 'pockets': 'Are there pockets?'}) as MYANSWERS\nFROM AVALANCHE.TRF.PRODUCTS_CLASSIFY;\n\nselect * from PRODUCTS_EXTRACT;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b77f9b05-1ad7-4ca8-b951-47bc3c20eb05",
   "metadata": {
    "name": "introLineage",
    "collapsed": false
   },
   "source": "As a data engineer, or a data steward, you often want to track the data lineage of an object. The GET_LINEAGE function allows you to get the path of objects upstream or downstream of an object. The syntax is \n\n```sql\nSNOWFLAKE.CORE.GET_LINEAGE(\n    '<object_name>',\n    '<object_domain>',\n    '<direction>',\n    [ <distance>, ]\n    [ '<object_version>' ]\n)\n```"
  },
  {
   "cell_type": "code",
   "id": "959110fe-3dbc-40eb-825b-13c4bc671aa4",
   "metadata": {
    "language": "sql",
    "name": "SQLLineage"
   },
   "outputs": [],
   "source": "SELECT\n    DISTANCE,\n    SOURCE_OBJECT_DOMAIN,\n    SOURCE_OBJECT_DATABASE,\n    SOURCE_OBJECT_SCHEMA,\n    SOURCE_OBJECT_NAME,\n    SOURCE_STATUS,\n    TARGET_OBJECT_DOMAIN,\n    TARGET_OBJECT_DATABASE,\n    TARGET_OBJECT_SCHEMA,\n    TARGET_OBJECT_NAME,\n    TARGET_STATUS,\nFROM TABLE (SNOWFLAKE.CORE.GET_LINEAGE(\n    'AVALANCHE.TRF.PRODUCTS_SUMMARIZE', \n    'TABLE', \n    'UPSTREAM', \n    6))\nORDER BY DISTANCE;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a4b18812-cb46-48f0-8990-a52c7ba1d6bf",
   "metadata": {
    "name": "introStreamlit",
    "collapsed": false
   },
   "source": "What's the point of all this data processing if you can't easily share and interact with the insights? This is where Streamlit steps in, allowing you to transform your data into a beautiful, interactive web application with just a few lines of Python code. Let's build a simple yet powerful dashboard to visualize our product data."
  },
  {
   "cell_type": "code",
   "id": "a15f7506-2721-4efc-a333-e65e603b7f94",
   "metadata": {
    "language": "python",
    "name": "PyTableToDataframe"
   },
   "outputs": [],
   "source": "SQLCleanOrders.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "33e99011-8f26-4a13-9024-e922c582ad82",
   "metadata": {
    "language": "python",
    "name": "PyStreamlit"
   },
   "outputs": [],
   "source": "import streamlit as st\nimport altair as alt\nimport pandas as pd\n\n# Ensure TOTAL_PRICE_NUM is numeric\nPyTableToDataframe['TOTAL_PRICE_NUM'] = pd.to_numeric(PyTableToDataframe['TOTAL_PRICE_NUM'])\n\n# Create the base chart with bars\nchart = alt.Chart(PyTableToDataframe).mark_bar(size=15).encode(\n    x=alt.X('ORDER_DATE:T',\n            axis=alt.Axis(\n                format='%Y-%m-%d',  # YYYY-MM-DD format\n                labelAngle=90)  # Rotate labels 90 degrees\n            ),\n    y=alt.Y('TOTAL_PRICE_NUM:Q'),\n    color=alt.condition(\n        alt.datum.TOTAL_PRICE_NUM >= 500,\n        alt.value('#2ecc71'),  # green for great\n        alt.value('#ffff01')   # yellow for not as impressive \n    ),\n    tooltip=['PRODUCT_NAME:N', 'ORDER_DATE:T'] # Add tooltip\n).properties(\n    height=500\n)\n\n# Display the chart\nst.altair_chart(chart, use_container_width=True)",
   "execution_count": null
  }
 ]
}